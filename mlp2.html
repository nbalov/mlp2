<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN"  
  "http://www.w3.org/TR/html4/loose.dtd">  
<html > 
<head><title></title> 
<meta http-equiv="Content-Type" content="text/html; charset=iso-8859-1"> 
<meta name="generator" content="TeX4ht (http://www.tug.org/tex4ht/)"> 
<meta name="originator" content="TeX4ht (http://www.tug.org/tex4ht/)"> 
<!-- html --> 
<meta name="src" content="mlp2blog.tex"> 
<meta name="date" content="2018-01-16 10:35:00"> 
<link rel="stylesheet" type="text/css" href="mlp2blog.css"> 
</head><body 
>
   <h3 class="likesectionHead"><a 
 id="x1-1000"></a>Handwritten digit classification using multilayer perceptron with 2 hidden
layers</h3>
<!--l. 20--><p class="noindent" >Nikolay Balov, Principal Statistician and Software Developer
<!--l. 23--><p class="noindent" >
   <h4 class="likesubsectionHead"><a 
 id="x1-2000"></a>Overview</h4>
<!--l. 25--><p class="noindent" >Image recognition has been historically one of the major application area of machine
learning. Many advanced technologies today incorporate algorithms for recognizing
handwritten letters and digits. The task poses challenges beyond the scope of
standard statistical methodology due to the structure and volume of image data, and
the complexity of the hierarchical models that are required to address it
effectively.
<!--l. 32--><p class="indent" >   In this blog I present an unofficial Stata command, <span 
class="cmbx-10">mlp2</span>, for specifying and
learning a simple class of neural networks, multilayer perceptrons with 2 hidden
layers, that can be useful for solving some machine learning problems. I demonstrate
an application of <span 
class="cmbx-10">mlp2 </span>to classifying handwritten digits from the MNIST database,
<a 
href="#Xlecun1998">Y.&#x00A0;LeCun and Haffner</a>&#x00A0;(<a 
href="#Xlecun1998">1998</a>).
<!--l. 38--><p class="indent" >   The <span 
class="cmtt-10">mlp2 </span>command can be installed by typing the following in Stata:
   <div class="stlog"> 
<div class="minipage"><div class="obeylines-v"><pre class="stlog">
<br />.&#x00A0;net&#x00A0;install&#x00A0;mlp2,&#x00A0;from("http://www.stata.com/users/nbalov")
<br /></pre></div>
</div>
</div> 

<!--l. 44--><p class="indent" >   To see the help file, type
   <div class="stlog"> 
<div class="minipage"><div class="obeylines-v"><pre class="stlog">
<br />.&#x00A0;help&#x00A0;mlp2
<br /></pre></div>
</div>
</div> 

<!--l. 50--><p class="noindent" >
   <h4 class="likesubsectionHead"><a 
 id="x1-3000"></a>Model description</h4>
<!--l. 52--><p class="noindent" >The perceptron is a computational model designed as a simple representation of the
biological neuron, <a 
href="#Xrosenblatt1958">Rosenblatt</a>&#x00A0;(<a 
href="#Xrosenblatt1958">1958</a>). It takes <span 
class="cmmi-10">p </span>input variables <span 
class="cmmi-10">x</span><sub><span 
class="cmmi-7">i</span></sub> and produces a
single binary output <span 
class="cmmi-10">y</span>, according to the function <span 
class="cmmi-10">y </span>= <span 
class="cmmi-10">f</span>(<span 
class="cmmi-10">b </span>+ <span 
class="cmex-10">&#x2211;</span>
  <sub><span 
class="cmmi-7">i</span><span 
class="cmr-7">=1</span></sub><sup><span 
class="cmmi-7">p</span></sup><span 
class="cmmi-10">w</span><sub><span 
class="cmmi-7">i</span></sub><span 
class="cmmi-10">x</span><sub><span 
class="cmmi-7">i</span></sub>), where <span 
class="cmmi-10">b </span>is a
bias term, <span 
class="cmmi-10">w</span><sub><span 
class="cmmi-7">i</span></sub>&#8217;s are some weights, and <span 
class="cmmi-10">f </span>is the Heaviside step function. In
machine learning literature, <span 
class="cmmi-10">f </span>is known as activation function. More concisely,
<span 
class="cmmi-10">f</span>(<span 
class="cmmi-10">x</span>) = 1<sub><span 
class="cmmi-7">x</span><sup><span 
class="cmmi-5">T</span></sup><span 
class="cmmi-7">w</span><span 
class="cmr-7">+</span><span 
class="cmmi-7">b&#x003E;</span><span 
class="cmr-7">0</span></sub>. This construction can be used for solving dichotomous
classification problems.
<!--l. 61--><p class="indent" >   <hr class="figure"><div class="figure" 
>
                                                                  

                                                                  
<a 
 id="x1-30011"></a>
                                                                  

                                                                  
<div class="center" 
>
<!--l. 62--><p class="noindent" >
<!--l. 63--><p class="noindent" ><img 
src="mlp2blog0x.png" alt="PIC" class="graphics" width="334.55171pt" height="233.52373pt" ><!--tex4ht:graphics  
name="mlp2blog0x.png" src="mlp2_graph.eps"  
-->
<br /> <div class="caption" 
><span class="id">Figure&#x00A0;1: </span><span  
class="content">Schematic of multilayer perceptron with 2 hidden layers.</span></div><!--tex4ht:label?: x1-30011 -->
</div>
                                                                  

                                                                  
<!--l. 66--><p class="indent" >   </div><hr class="endfigure">
<!--l. 68--><p class="indent" >   The inability of the original perceptron to resolve classes that are not linearly
separable let to the development of perceptrons with 2 or more layers, different
activation functions and multiclass output support. These multilayer models
belong to the more general class of feed-forward artificial networks. In this
blog I consider a 3-level multilayer perceptron. Excluding the input, the
model has 2 hidden layers and an output layer. It is formally defined by
the following set of equations. Let <span 
class="cmmi-10">x</span><sub><span 
class="cmmi-7">i</span></sub>, <span 
class="cmmi-10">i </span>= 1<span 
class="cmmi-10">,</span><span 
class="cmmi-10">&#x2026;</span><span 
class="cmmi-10">,p </span>be the input variables, <span 
class="cmmi-10">u</span><sub><span 
class="cmmi-7">j</span></sub>,
<span 
class="cmmi-10">j </span>= 1<span 
class="cmmi-10">,</span><span 
class="cmmi-10">&#x2026;</span><span 
class="cmmi-10">,m</span><sub><span 
class="cmr-7">1</span></sub> be the variables of the first hidden layer, <span 
class="cmmi-10">v</span><sub><span 
class="cmmi-7">k</span></sub>, <span 
class="cmmi-10">k </span>= 1<span 
class="cmmi-10">,</span><span 
class="cmmi-10">&#x2026;</span><span 
class="cmmi-10">,m</span><sub><span 
class="cmr-7">2</span></sub> be
variables of the second layer, and <span 
class="cmmi-10">y</span><sub><span 
class="cmmi-7">l</span></sub>, <span 
class="cmmi-10">l </span>= 1<span 
class="cmmi-10">,</span><span 
class="cmmi-10">&#x2026;</span><span 
class="cmmi-10">,c </span>be the output class variables,
then
   <center class="math-display" >
<img 
src="mlp2blog1x.png" alt="               &#x2211;p
uj = ReLU (&#x03B1;0j +  &#x03B1;ijxi), j = 1,...,m1
               i=1
" class="math-display" ></center>
   <center class="math-display" >
<img 
src="mlp2blog2x.png" alt="                m&#x2211;1
vk = ReLU (&#x03B2;0k +    &#x03B2;jkuj), k = 1,...,m2
                j=1
" class="math-display" ></center>
   <center class="math-display" >
<img 
src="mlp2blog3x.png" alt="         m&#x2211;2
zl = &#x03B3;0l +  &#x03B3;klvk, l = 1,...,c
         k=1
" class="math-display" ></center>
   <center class="math-display" >
<img 
src="mlp2blog4x.png" alt="y = f (z), l = 1...c
 l   l
" class="math-display" ></center>
<!--l. 92--><p class="indent" >   where <span 
class="cmmi-10">ReLU </span>is the rectified linear unit function, <span 
class="cmmi-10">ReLU</span>(<span 
class="cmmi-10">x</span>) = max<span 
class="cmsy-10">{</span>0<span 
class="cmmi-10">,x</span><span 
class="cmsy-10">} </span>(due to
its effectiveness in practice, <span 
class="cmmi-10">ReLU </span>became a preferred activation function in
feed-forward networks) and <span 
class="cmmi-10">f </span>is the so called <span 
class="cmti-10">softmax </span>function known from the
multinomial logistic regression model
   <center class="math-display" >
<img 
src="mlp2blog5x.png" alt="f (z) = &#x2211;--exp-(zl)--, l = 1,...,c
 l       cq=1exp(zq)
" class="math-display" ></center>
<!--l. 101--><p class="indent" >   Given a training sample <span 
class="cmsy-10">{</span>(<span 
class="cmmi-10">x</span><sup><span 
class="cmmi-7">s</span></sup><span 
class="cmmi-10">,y</span><sup><span 
class="cmmi-7">s</span></sup>)<span 
class="cmsy-10">}</span><sub><span 
class="cmmi-7">s</span><span 
class="cmr-7">=1</span></sub><sup><span 
class="cmmi-7">n</span></sup>, a loss function is defined to be the
negative log-likelihood of parameters <span 
class="cmmi-10">z</span><sub><span 
class="cmmi-7">l</span></sub><sup><span 
class="cmmi-7">s</span></sup> with respect to the sample,
   <center class="math-display" >
<img 
src="mlp2blog6x.png" alt=" n      c
&#x2211;  {log(&#x2211;  exp(zs)) - zss}
s=1    l=1     l    y " class="math-display" ></center>
which is an implicit function of all model parameters <span 
class="cmmi-10">&#x03B1;</span>, <span 
class="cmmi-10">&#x03B2;</span>, and <span 
class="cmmi-10">&#x03B3;</span>. The total number
                                                                  

                                                                  
of parameters is <span 
class="cmmi-10">m</span><sub><span 
class="cmr-7">1</span></sub>(<span 
class="cmmi-10">p </span>+ 1) + <span 
class="cmmi-10">m</span><sub><span 
class="cmr-7">2</span></sub>(<span 
class="cmmi-10">m</span><sub><span 
class="cmr-7">1</span></sub> + 1) + <span 
class="cmmi-10">c</span>(<span 
class="cmmi-10">m</span><sub><span 
class="cmr-7">2</span></sub> + 1).
<!--l. 109--><p class="indent" >   The training involves finding a set of parameters that minimize the loss function.
Note that the loss function is non-convex in general and may not have a
global minimum. The goal is to find optimal parameters such that the model
generalizes well to new data in terms of prediction accuracy. The mainstream
method for learning multilayer perceptrons, and feed-forward networks in
general, is stochastic gradient descent and its derivatives. The gradients are
computed using the backpropagation algorithm, <a 
href="#Xrumelhart1986">David E.&#x00A0;Rumelhart and
Williams</a>&#x00A0;(<a 
href="#Xrumelhart1986">1986</a>).
<!--l. 117--><p class="indent" >   In Figure 1 I show an example model that can be specified by the <span 
class="cmbx-10">mlp2</span>
command. It has 3 input variables, 2 hidden layers with 4 neurons each, and a 2-class
output, that is, the output layer implements logistic regression.
   <h4 class="likesubsectionHead"><a 
 id="x1-4000"></a>Classifying handwritten digits from the MNIST database</h4>
<!--l. 123--><p class="noindent" >The MNIST database, which stands for Modified National Institute of Standards and
Technology, is a collection of images of handwritten numerals. It is a popular
benchmark dataset used for evaluation of image recognition systems. A substantial
list of existing statistical and machine learning classification algorithms have been
tested and evaluated on MNIST. See http://yann.lecun.com/exdb/mnist for current
testing results and literature.
<!--l. 130--><p class="indent" >   I have converted the MNIST database into two Stata datasets, <span 
class="cmti-10">mnist-train </span>and
<span 
class="cmti-10">mnist-test</span>. The training dataset, <span 
class="cmti-10">mnist-train</span>, contains 60,000 images. The test
dataset, <span 
class="cmti-10">mnist-test</span>, contains 10,000 images. Each image has dimensions 28<span 
class="cmsy-10">&#x00D7;</span>28 with
total of 784 pixels. The image pixels are stacked horizontally and are represented by
the variables <span 
class="cmbx-10">v1 </span>to <span 
class="cmbx-10">v784</span>. The original images are monochrome and are encoded
using 1 byte per pixel. In the Stata datasets, the images have been reformatted so
that each pixel is represented by a float number in the [0<span 
class="cmmi-10">,</span>1] range. The variable
<span 
class="cmbx-10">y </span>is the label variable with values from 0 to 9 corresponding to the digit
represented in the image. In Figure 2 you can see some examples from the training
dataset.
<!--l. 143--><p class="indent" >   <hr class="figure"><div class="figure" 
>
                                                                  

                                                                  
<a 
 id="x1-40012"></a>
                                                                  

                                                                  
<div class="center" 
>
<!--l. 144--><p class="noindent" >
<!--l. 145--><p class="noindent" ><img 
src="mlp2blog7x.png" alt="PIC" class="graphics" width="317.9892pt" height="231.26486pt" ><!--tex4ht:graphics  
name="mlp2blog7x.png" src="mnist/eps/digits10.eps"  
-->
<br /> <div class="caption" 
><span class="id">Figure&#x00A0;2: </span><span  
class="content">Records of handwritten digits from the MNIST database</span></div><!--tex4ht:label?: x1-40012 -->
</div>
                                                                  

                                                                  
<!--l. 148--><p class="indent" >   </div><hr class="endfigure">
<!--l. 150--><p class="indent" >   Visualizing individual images is unfortunately a bit cumbersome for it requires
some manipulations with the dataset. I need to extract an individual record and
expand its pixel values in a new long-format dataset. Then I use the <span 
class="cmbx-10">twoway</span>
<span 
class="cmbx-10">contour </span>command with the <span 
class="cmbx-10">heatmap </span>option to draw it. In Figure 3 I show the first
record from the training dataset.
   <div class="stlog"> 
<div class="minipage"><div class="obeylines-v"><pre class="stlog">
<br />.&#x00A0;use&#x00A0;mnist-train
<br />(Training&#x00A0;MNIST:&#x00A0;28x28&#x00A0;images&#x00A0;with&#x00A0;stacked&#x00A0;pixel&#x00A0;values&#x00A0;v*&#x00A0;in&#x00A0;[0,1]&#x00A0;range)
<br />
<br />.&#x00A0;drop&#x00A0;y
<br />
<br />.&#x00A0;quietly&#x00A0;keep&#x00A0;if&#x00A0;_n==1
<br />
<br />.&#x00A0;generate&#x00A0;y&#x00A0;=&#x00A0;1
<br />
<br />.&#x00A0;quietly&#x00A0;reshape&#x00A0;long&#x00A0;v,&#x00A0;i(y)&#x00A0;j(x)
<br />
<br />.&#x00A0;quietly&#x00A0;replace&#x00A0;y&#x00A0;=&#x00A0;28-floor((x-1)/28)
<br />
<br />.&#x00A0;quietly&#x00A0;replace&#x00A0;x&#x00A0;=&#x00A0;x&#x00A0;-&#x00A0;28*(28-y)
<br />
<br />.&#x00A0;twoway&#x00A0;contour&#x00A0;v&#x00A0;y&#x00A0;x,&#x00A0;heatmap&#x00A0;&#x00A0;crule(intensity)&#x00A0;ecolor(black)&#x00A0;&#x00A0;&#x00A0;///
<br />&#x003E;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;clegend(off)&#x00A0;yscale(off)&#x00A0;xscale(off)&#x00A0;legend(off)&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;///
<br />&#x003E;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;graphregion(margin(zero))&#x00A0;plotregion(margin(zero))&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;///
<br />&#x003E;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;graphregion(color(white))&#x00A0;aspectratio(1)
<br /></pre></div></div>
</div> 
 <hr class="figure"><div class="figure" 
>
                                                                  

                                                                  
<a 
 id="x1-40023"></a>
                                                                  

                                                                  
<div class="center" 
>
<!--l. 160--><p class="noindent" >
<!--l. 161--><p class="noindent" ><img 
src="mlp2blog8x.png" alt="PIC" class="graphics" width="158.99156pt" height="115.63022pt" ><!--tex4ht:graphics  
name="mlp2blog8x.png" src="mnist/eps/digit1.eps"  
-->
<br /> <div class="caption" 
><span class="id">Figure&#x00A0;3: </span><span  
class="content">The first observation in the training dataset is the digit 5.</span></div><!--tex4ht:label?: x1-40023 -->
</div>
                                                                  

                                                                  
<!--l. 164--><p class="indent" >   </div><hr class="endfigure">
<!--l. 166--><p class="indent" >   I proceed with our main task - the classification of handwritten digits in the
MNIST database. I will train a 3-layer perceptron with 2 hidden layers,
each having 100 neurons, <span 
class="cmmi-10">m</span><sub><span 
class="cmr-7">1</span></sub> = <span 
class="cmmi-10">m</span><sub><span 
class="cmr-7">2</span></sub> = 100. The number of input variables
is <span 
class="cmmi-10">p </span>= 784 and the number of output variables, class labels, is <span 
class="cmmi-10">c </span>= 10.
The total number of parameters in our model is thus quite substantial,
100 <span 
class="cmsy-10">* </span>(784 + 1) + 100 <span 
class="cmsy-10">* </span>(100 + 1) + 10 <span 
class="cmsy-10">* </span>(100 + 1) = 89610.
<!--l. 173--><p class="indent" >   I start by loading the training dataset in Stata.
   <div class="stlog"> 
<div class="minipage"><div class="obeylines-v"><pre class="stlog">
<br />.&#x00A0;use&#x00A0;mnist-train
<br />(Training&#x00A0;MNIST:&#x00A0;28x28&#x00A0;images&#x00A0;with&#x00A0;stacked&#x00A0;pixel&#x00A0;values&#x00A0;v*&#x00A0;in&#x00A0;[0,1]&#x00A0;range)
<br /></pre></div></div>
</div> 

<!--l. 179--><p class="indent" >   Then I fit the model using the <span 
class="cmbx-10">mlp2 fit </span>command following the standard Stata
syntax by specifying the dependent variable <span 
class="cmbx-10">y </span>and pixel values as the independent
covariates <span 
class="cmbx-10">v*</span>. The only options I add are the size of the 2 hidden layers,
<span 
class="cmbx-10">layer1(100) </span>and <span 
class="cmbx-10">layer2(100)</span>. All additional options pertaining to the
optimization algorithm are left at default values; type <span 
class="cmbx-10">help mlp2 </span>to see
them.
   <div class="stlog"> 
<div class="minipage"><div class="obeylines-v"><pre class="stlog">
<br />.&#x00A0;set&#x00A0;seed&#x00A0;12345
<br />
<br />.&#x00A0;mlp2&#x00A0;fit&#x00A0;y&#x00A0;v*,&#x00A0;layer1(100)&#x00A0;layer2(100)
<br /></pre></div></div>
</div> 

<!--l. 190--><p class="indent" >   The <span 
class="cmbx-10">mlp2 fit </span>command proceed silently and does not print any relevant
estimation results. You can print some additional information and follow the progress
of the loss value if you specify the <span 
class="cmbx-10">echo() </span>option. If you specify <span 
class="cmbx-10">echo(1)</span>, you will
observe that the loss decreases from the starting value of 0.2823 to 0.0008 after 20
iterations of stochastic gradient descent with the default batch size of 50. Note
that the default optimization options may not work well for your, different,
dataset.
<!--l. 198--><p class="indent" >   The found optimal values of the parameters are saved in the matrices <span 
class="cmbx-10">e(alpha)</span>,
<span 
class="cmbx-10">e(alpha0)</span>, <span 
class="cmbx-10">e(beta)</span>, <span 
class="cmbx-10">e(beta0)</span>, <span 
class="cmbx-10">e(gamma)</span>, and <span 
class="cmbx-10">e(gamma0)</span>, corresponding to the
coefficients and intercepts of the 3 layers. The actual estimates do not provide
much insights for understanding the model so I have no further comments on
them.
<!--l. 204--><p class="indent" >   I then perform in-sample prediction using the <span 
class="cmbx-10">mlp2 predict </span>command to
evaluate the fit of the model. The option <span 
class="cmbx-10">genvar(ypred) </span>provides a stub for new
variables holding the predicted class probabilities. The command will thus generate
variables <span 
class="cmbx-10">ypred</span><span 
class="cmbx-10">_0 </span>to <span 
class="cmbx-10">ypred</span><span 
class="cmbx-10">_9 </span>of probability values that sum to 1. The digit with
maximum probability will be the predicted one used for calculating the prediction
accuracy. The accuracy itself is given by the proportion of correctly predicted digits
in the sample.
   <div class="stlog"> 
<div class="minipage"><div class="obeylines-v"><pre class="stlog">
<br />.&#x00A0;mlp2&#x00A0;predict,&#x00A0;genvar(ypred)
<br />
<br />Prediction&#x00A0;accuracy:&#x00A0;.99995
<br />
<br /></pre></div></div>
</div> 

                                                                  

                                                                  
<!--l. 216--><p class="indent" >   The reported in-sample prediction accuracy of about 1 shows that the
model explains the training data almost perfectly. This itself is not enough
indication for a good model fit. The model is so complex that it can easily
overfit even large training samples. The important problem of designing and
training efficient models without overfitting is, however, out of the scope of this
blog.
<!--l. 222--><p class="indent" >   The real evaluation of the model is based on its prediction accuracy on
independent sample that is not used for training. For the purpose I use the <span 
class="cmti-10">mnist-test</span>
dataset.
   <div class="stlog"> 
<div class="minipage"><div class="obeylines-v"><pre class="stlog">
<br />.&#x00A0;use&#x00A0;mnist-test,&#x00A0;clear
<br />(Testing&#x00A0;MNIST:&#x00A0;28x28&#x00A0;images&#x00A0;with&#x00A0;stacked&#x00A0;pixel&#x00A0;values&#x00A0;v*&#x00A0;in&#x00A0;[0,1]&#x00A0;range)
<br /></pre></div></div>
</div> 

   <div class="stlog"> 
<div class="minipage"><div class="obeylines-v"><pre class="stlog">
<br />.&#x00A0;mlp2&#x00A0;predict,&#x00A0;genvar(ypred)
<br />
<br />Prediction&#x00A0;accuracy:&#x00A0;.9727
<br />
<br /></pre></div></div>
</div> 

<!--l. 234--><p class="indent" >   The reported test prediction accuracy is about 0.97, so the test error is less than
3%. This is a reassuring result, inline with the performance of other similar
classification models. See for example the [3-layer NN, 500+150 hidden units] model
listed in the classification table in http://yann.lecun.com/exdb/mnist. The best
performing classifiers have less than 0.5% error but employ substantially more
elaborate models than the presented here.
<!--l. 242--><p class="indent" >   It is instructive to look at some of the test digits that are missclassified. The
indices of the missclassified records are saved in the matrix <span 
class="cmbx-10">e(pred</span><span 
class="cmbx-10">_err</span><span 
class="cmbx-10">_ind)</span>.
Some of them are 116, 152, 246, and 322. As seen from the predicted class
probability vector, the test image 116 depicts the digit 4 but it is classified as 9.
<div class="stlog"> 
<div class="minipage"><div class="obeylines-v"><pre class="stlog">
<br />.&#x00A0;list&#x00A0;y&#x00A0;ypred*&#x00A0;in&#x00A0;116
<br />
<br />&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;   ---+----------+----------+----------+----------+----------+---------- 
<br />116.&#x00A0;|&#x00A0;y&#x00A0;|&#x00A0;&#x00A0;ypred_0&#x00A0;|&#x00A0;&#x00A0;ypred_1&#x00A0;|&#x00A0;&#x00A0;ypred_2&#x00A0;|&#x00A0;&#x00A0;ypred_3&#x00A0;|&#x00A0;&#x00A0;ypred_4&#x00A0;|&#x00A0;&#x00A0;ypred_5&#x00A0;|
<br />&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;|&#x00A0;4&#x00A0;|&#x00A0;7.98e-09&#x00A0;|&#x00A0;5.25e-07&#x00A0;|&#x00A0;1.79e-08&#x00A0;|&#x00A0;1.94e-07&#x00A0;|&#x00A0;.0088738&#x00A0;|&#x00A0;5.35e-06&#x00A0;|
<br />&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;+---+----------+-+--------+-------+--+----------+---+------+----------+
<br />&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;|&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;ypred_6&#x00A0;&#x00A0;&#x00A0;&#x00A0;|&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;ypred_7&#x00A0;&#x00A0;&#x00A0;&#x00A0;|&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;ypred_8&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;|&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;ypred_9&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;|
<br />&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;|&#x00A0;&#x00A0;&#x00A0;&#x00A0;.0000412&#x00A0;&#x00A0;&#x00A0;&#x00A0;|&#x00A0;&#x00A0;&#x00A0;&#x00A0;1.76e-09&#x00A0;&#x00A0;&#x00A0;&#x00A0;|&#x00A0;&#x00A0;&#x00A0;&#x00A0;3.56e-06&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;|&#x00A0;&#x00A0;&#x00A0;&#x00A0;.9910753&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0;|
<br />&#x00A0;&#x00A0;&#x00A0;&#x00A0;&#x00A0; ----------------+----------------+-----------------+----------------- 
<br /></pre></div></div>
</div> 
 By looking at test image 116 (Figure 4), we indeed see a resemblance with the digit
9, so it is not surprising the algorithm has been fooled.
<!--l. 253--><p class="indent" >   Similarly you can check that test image 152 depicts the digit 9 but it is classified
as 8, test image 246 depicts the digit 39 but it is classified as 6, and t est image 322
depicts the digit 2 but it is classified as 7. I show these test images in Figure
4.
<!--l. 258--><p class="indent" >   <hr class="figure"><div class="figure" 
>
                                                                  

                                                                  
<a 
 id="x1-40034"></a>
                                                                  

                                                                  
<div class="center" 
>
<!--l. 259--><p class="noindent" >
<!--l. 260--><p class="noindent" ><img 
src="mlp2blog9x.png" alt="PIC" class="graphics" width="317.98975pt" height="79.49744pt" ><!--tex4ht:graphics  
name="mlp2blog9x.png" src="mnist/eps/wrong_pred4.eps"  
-->
<br /> <div class="caption" 
><span class="id">Figure&#x00A0;4: </span><span  
class="content">The incorrectly classified test images 115, 152, 246 and 322.</span></div><!--tex4ht:label?: x1-40034 -->
</div>
                                                                  

                                                                  
<!--l. 263--><p class="indent" >   </div><hr class="endfigure">
   <h4 class="likesubsectionHead"><a 
 id="x1-5000"></a>Conclusion</h4>
<!--l. 267--><p class="noindent" >I have presented a 3-level perceptron model as a non-trivial example of feed-forward
artificial network. I demonstrated its effectiveness in a challenging problem such as
the classification of handwritten numerals from the MNIST database. This
test case however is not the ideal application of the model. The multilayer
perceptron is suitable for analyzing data with no apparent relationship between
variables. Pixels in images, on the other hand, are spatially correlated. It
is not surprising then that among best performing MNIST classifiers are
models that exploit the spatial correlation such as the convolutional neural
networks.
<!--l. 3--><p class="noindent" >
   <h3 class="likesectionHead"><a 
 id="x1-6000"></a>References</h3>
<!--l. 3--><p class="noindent" >
  <div class="thebibliography">
  <p class="bibitem" ><span class="biblabel">
<a 
 id="Xrumelhart1986"></a><span class="bibsp">&#x00A0;&#x00A0;&#x00A0;</span></span>David  E.&#x00A0;Rumelhart,  G.  E.&#x00A0;H.,  and  R.&#x00A0;J.  Williams.  1986.    Learning
  representations by back-propagating errors. <span 
class="cmti-10">Nature </span>323(6088): 533536.
  </p>
  <p class="bibitem" ><span class="biblabel">
<a 
 id="Xrosenblatt1958"></a><span class="bibsp">&#x00A0;&#x00A0;&#x00A0;</span></span>Rosenblatt, F. 1958. The Perceptron: A Probabilistic Model for Information
  Storage and Organization in the Brain.   <span 
class="cmti-10">Cornell Aeronautical Laboratory,</span>
  <span 
class="cmti-10">Psychological Review </span>65(6): 386408.
  </p>
  <p class="bibitem" ><span class="biblabel">
<a 
 id="Xlecun1998"></a><span class="bibsp">&#x00A0;&#x00A0;&#x00A0;</span></span>Y.&#x00A0;LeCun,  Y.&#x00A0;B.,  L.&#x00A0;Bottou,  and  P.&#x00A0;Haffner.  1998.     Gradient-Based
  Learning Applied to Document Recognition. <span 
class="cmti-10">Proceedings of the IEEE </span>86(11):
  2278&#8211;2324.
</p>
  </div>
    
</body></html> 

                                                                  

